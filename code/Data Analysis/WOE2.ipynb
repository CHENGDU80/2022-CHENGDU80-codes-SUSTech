{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd5bfca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b5d3265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_woe_iv(dataset):\n",
    "    \"\"\"\n",
    "    对分箱后的特征计算WOE和IV\n",
    "    :param dataset:DataFrame，计算数据,需要在特征分箱后的数据\n",
    "    :return:\n",
    "        iv: float，iv值\n",
    "        df:DataFrame，woe和IV计算后结果\n",
    "\n",
    "    Example\n",
    "    -----------------------------------------------------------------\n",
    "    >>> import random\n",
    "    >>> data = pd.DataFrame([[random.random(),random.randint(0,1)] for _ in range(500)],columns=['feature','label'])\n",
    "    >>> df = cut_width(dataset=data,inputcol='feature',labelcol='label',bins=10)\n",
    "    >>> df.rename(columns={0:'neg',1:'pos'},inpalce=True)\n",
    "    >>> iv, woe_iv_df = calculate_woe_iv(dataset=df)\n",
    "    >>> iv\n",
    "    0.037619588549634465\n",
    "    >>> woe_iv_df\n",
    "    label               neg  pos  pos_rate  neg_rate       woe        iv\n",
    "    feature\n",
    "    (-0.000313, 0.103]   23   27  0.104869  0.103004  0.017940  0.000033\n",
    "    (0.103, 0.206]       23   27  0.104869  0.103004  0.017940  0.000033\n",
    "    (0.206, 0.312]       29   21  0.082397  0.128755 -0.446365  0.020693\n",
    "    (0.312, 0.418]       22   28  0.108614  0.098712  0.095591  0.000947\n",
    "    (0.418, 0.535]       19   31  0.119850  0.085837  0.333793  0.011353\n",
    "    (0.535, 0.614]       22   28  0.108614  0.098712  0.095591  0.000947\n",
    "    (0.614, 0.705]       24   26  0.101124  0.107296 -0.059249  0.000366\n",
    "    (0.705, 0.8]         24   26  0.101124  0.107296 -0.059249  0.000366\n",
    "    (0.8, 0.891]         22   28  0.108614  0.098712  0.095591  0.000947\n",
    "    (0.891, 0.991]       25   25  0.097378  0.111588 -0.136210  0.001936\n",
    "    \"\"\"\n",
    "    df = copy.copy(dataset)\n",
    "    df['pos_rate'] = (df['pos'] + 1) / df['pos'].sum()  # 计算每个分组内的响应（Y=1）占比，加1为了防止在计算woe时分子分母为0\n",
    "    df['neg_rate'] = (df['neg'] + 1) / df['neg'].sum()  # 计算每个分组内的未响应（Y=0）占比\n",
    "    df['woe'] = np.log(df['pos_rate'] / df['neg_rate'])  # 计算每个分组的WOE\n",
    "    df['iv'] = (df['pos_rate'] - df['neg_rate']) * df['woe']  # 计算每个分组的IV\n",
    "    iv = df['iv'].sum()\n",
    "    return iv, df\n",
    "    \n",
    "def cut_width(dataset, inputcol, labelcol='label', bins=10):\n",
    "    \"\"\"\n",
    "    等宽分箱\n",
    "    :param dataset: DataFrame，计算数据\n",
    "    :param inputcol: String,待分箱列列名\n",
    "    :param labelcol: String,目标列列名\n",
    "    :param bins: int,正整数，分箱数\n",
    "    :return:\n",
    "    :return:\n",
    "        df: DataFrame，分箱后结果\n",
    "\n",
    "    Example\n",
    "    -----------------------------------------------------------------\n",
    "    >>> import random\n",
    "    >>> data = pd.DataFrame([[random.random(),random.randint(0,1)] for _ in range(500)],columns=['feature','label'])\n",
    "    >>> df = cut_width(data,inputcol='feature',labelcol='label',bins=10)\n",
    "    >>> df\n",
    "        label                             good  bad\n",
    "    feature\n",
    "    (-0.0009308000000000001, 0.0968]    23   27\n",
    "    (0.0968, 0.188]                     27   23\n",
    "    (0.188, 0.29]                       25   25\n",
    "    (0.29, 0.385]                       32   18\n",
    "    (0.385, 0.472]                      31   19\n",
    "    (0.472, 0.567]                      24   26\n",
    "    (0.567, 0.686]                      24   26\n",
    "    (0.686, 0.778]                      24   26\n",
    "    (0.778, 0.912]                      26   24\n",
    "    (0.912, 0.999]                      29   21\n",
    "    \"\"\"\n",
    "    df = copy.copy(dataset)\n",
    "    df[inputcol] = pd.qcut(x=df[inputcol], q=bins)\n",
    "    df = pd.crosstab(index=df[inputcol], columns=df[labelcol], margins=False)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03fb6d44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input array must be 1 dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3441/1685315270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'v'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mvar_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcut_width\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minputcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DEFAULT_LABEL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3441/3234539657.py\u001b[0m in \u001b[0;36mcut_width\u001b[0;34m(dataset, inputcol, labelcol, bins)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \"\"\"\n\u001b[1;32m     70\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabelcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \"\"\"\n\u001b[1;32m    363\u001b[0m     \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_preprocess_for_cut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_coerce_to_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_preprocess_for_cut\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input array must be 1 dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input array must be 1 dimensional"
     ]
    }
   ],
   "source": [
    "train_f = pd.read_csv(\"./data/train/feature.csv\")\n",
    "train_l = pd.read_csv(\"./data/train/label.csv\")\n",
    "df = pd.merge(train_f, train_l)\n",
    "\n",
    "var_list = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        for k in range(10):\n",
    "            var = 'v' + str(i) + str(j) + str(k)\n",
    "            var_list.append(var)\n",
    "df = cut_width(df,inputcol=var_list,labelcol='DEFAULT_LABEL',bins=10)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0852c7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, os, re, math, time\n",
    "# to check monotonicity of a series 检验序列的单调性\n",
    "def is_monotonic(temp_series):\n",
    "    return all(temp_series[i] <= temp_series[i + 1] for i in range(len(temp_series) - 1)) or all(temp_series[i] >= temp_series[i + 1] for i in range(len(temp_series) - 1))\n",
    "\n",
    "def prepare_bins(bin_data, c_i, target_col, max_bins):\n",
    "    force_bin = True\n",
    "    binned = False\n",
    "    remarks = np.nan\n",
    "    # ----------------- Monotonic binning -----------------\n",
    "    for n_bins in range(max_bins, 2, -1):\n",
    "        try:\n",
    "            bin_data[c_i + \"_bins\"] = pd.qcut(bin_data[c_i], n_bins, duplicates=\"drop\")\n",
    "            monotonic_series = bin_data.groupby(c_i + \"_bins\")[target_col].mean().reset_index(drop=True)\n",
    "            if is_monotonic(monotonic_series):\n",
    "                force_bin = False\n",
    "                binned = True\n",
    "                remarks = \"binned monotonically\"\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    # ----------------- Force binning -----------------\n",
    "    # creating 2 bins forcefully because 2 bins will always be monotonic\n",
    "    if force_bin or (c_i + \"_bins\" in bin_data and bin_data[c_i + \"_bins\"].nunique() < 2):\n",
    "        _min=bin_data[c_i].min()\n",
    "        _mean=bin_data[c_i].mean()\n",
    "        _max=bin_data[c_i].max()\n",
    "        bin_data[c_i + \"_bins\"] = pd.cut(bin_data[c_i], [_min, _mean, _max], include_lowest=True)\n",
    "        if bin_data[c_i + \"_bins\"].nunique() == 2:\n",
    "            binned = True\n",
    "            remarks = \"binned forcefully\"\n",
    "    \n",
    "    if binned:\n",
    "        return c_i + \"_bins\", remarks, bin_data[[c_i, c_i+\"_bins\", target_col]].copy()\n",
    "    else:\n",
    "        remarks = \"couldn't bin\"\n",
    "        return c_i, remarks, bin_data[[c_i, target_col]].copy()\n",
    "\n",
    "# calculate WOE and IV for every group/bin/class for a provided feature 计算所提供功能的每个组/箱/类的WOE和IV\n",
    "def iv_woe_4iter(binned_data, target_col, class_col):\n",
    "    if \"_bins\" in class_col:\n",
    "        binned_data[class_col] = binned_data[class_col].cat.add_categories(['Missing'])\n",
    "        binned_data[class_col] = binned_data[class_col].fillna(\"Missing\")\n",
    "        temp_groupby = binned_data.groupby(class_col).agg({class_col.replace(\"_bins\", \"\"):[\"min\", \"max\"],\n",
    "                                                           target_col: [\"count\", \"sum\", \"mean\"]}).reset_index()\n",
    "    else:\n",
    "        binned_data[class_col] = binned_data[class_col].fillna(\"Missing\")\n",
    "        temp_groupby = binned_data.groupby(class_col).agg({class_col:[\"first\", \"first\"],\n",
    "                                                           target_col: [\"count\", \"sum\", \"mean\"]}).reset_index()\n",
    "    \n",
    "    temp_groupby.columns = [\"sample_class\", \"min_value\", \"max_value\", \"sample_count\", \"event_count\", \"event_rate\"]\n",
    "    temp_groupby[\"non_event_count\"] = temp_groupby[\"sample_count\"] - temp_groupby[\"event_count\"]\n",
    "    temp_groupby[\"non_event_rate\"] = 1 - temp_groupby[\"event_rate\"]\n",
    "    temp_groupby = temp_groupby[[\"sample_class\", \"min_value\", \"max_value\", \"sample_count\",\n",
    "                                 \"non_event_count\", \"non_event_rate\", \"event_count\", \"event_rate\"]]\n",
    "    \n",
    "    if \"_bins\" not in class_col and \"Missing\" in temp_groupby[\"min_value\"]:\n",
    "        temp_groupby[\"min_value\"] = temp_groupby[\"min_value\"].replace({\"Missing\": np.nan})\n",
    "        temp_groupby[\"max_value\"] = temp_groupby[\"max_value\"].replace({\"Missing\": np.nan})\n",
    "    temp_groupby[\"feature\"] = class_col\n",
    "    if \"_bins\" in class_col:\n",
    "        temp_groupby[\"sample_class_label\"]=temp_groupby[\"sample_class\"].replace({\"Missing\": np.nan}).astype('category').cat.codes.replace({-1: np.nan})\n",
    "    else:\n",
    "        temp_groupby[\"sample_class_label\"]=np.nan\n",
    "    temp_groupby = temp_groupby[[\"feature\", \"sample_class\", \"sample_class_label\", \"sample_count\", \"min_value\", \"max_value\",\n",
    "                                 \"non_event_count\", \"non_event_rate\", \"event_count\", \"event_rate\"]]\n",
    "    \n",
    "    \"\"\"\n",
    "    **********get distribution of good and bad 得到好的和坏的分布\n",
    "    \"\"\"\n",
    "    temp_groupby['distbn_non_event'] = temp_groupby[\"non_event_count\"]/temp_groupby[\"non_event_count\"].sum()\n",
    "    temp_groupby['distbn_event'] = temp_groupby[\"event_count\"]/temp_groupby[\"event_count\"].sum()\n",
    "\n",
    "    temp_groupby['woe'] = np.log(temp_groupby['distbn_non_event'] / temp_groupby['distbn_event'])\n",
    "    temp_groupby['iv'] = (temp_groupby['distbn_non_event'] - temp_groupby['distbn_event']) * temp_groupby['woe']\n",
    "    \n",
    "    temp_groupby[\"woe\"] = temp_groupby[\"woe\"].replace([np.inf,-np.inf],0)\n",
    "    temp_groupby[\"iv\"] = temp_groupby[\"iv\"].replace([np.inf,-np.inf],0)\n",
    "    \n",
    "    return temp_groupby\n",
    "\n",
    "\"\"\"\n",
    "- iterate over all features. 迭代所有功能。\n",
    "- calculate WOE & IV for there classes.计算这些类别的woe与iv值\n",
    "- append to one DataFrame woe_iv.追加到数据帧woe_iv中。\n",
    "\"\"\"\n",
    "def var_iter(data, target_col, max_bins):\n",
    "    woe_iv = pd.DataFrame()\n",
    "    remarks_list = []\n",
    "    for c_i in data.columns:\n",
    "        if c_i not in [target_col]:\n",
    "            # check if binning is required. if yes, then prepare bins and calculate woe and iv.\n",
    "            \"\"\"\n",
    "            ----logic---\n",
    "            binning is done only when feature is continuous and non-binary. 仅当数据是连续型，且不是二进制时才会处理\n",
    "            Note: Make sure dtype of continuous columns in dataframe is not object. 确保dataframe中连续列的数据类型不是object。\n",
    "            \"\"\"\n",
    "            c_i_start_time=time.time()\n",
    "            if np.issubdtype(data[c_i], np.number) and data[c_i].nunique() > 2:\n",
    "                class_col, remarks, binned_data = prepare_bins(data[[c_i, target_col]].copy(), c_i, target_col, max_bins)\n",
    "                agg_data = iv_woe_4iter(binned_data.copy(), target_col, class_col)\n",
    "                remarks_list.append({\"feature\": c_i, \"remarks\": remarks})\n",
    "            else:\n",
    "                agg_data = iv_woe_4iter(data[[c_i, target_col]].copy(), target_col, c_i)\n",
    "                remarks_list.append({\"feature\": c_i, \"remarks\": \"categorical\"})\n",
    "            # print(\"---{} seconds. c_i: {}----\".format(round(time.time() - c_i_start_time, 2), c_i))\n",
    "            woe_iv = woe_iv.append(agg_data)\n",
    "    return woe_iv, pd.DataFrame(remarks_list)\n",
    "\n",
    "# after getting woe and iv for all classes of features calculate aggregated IV values for features.\n",
    "def get_iv_woe(data, target_col, max_bins):\n",
    "    func_start_time = time.time()\n",
    "    woe_iv, binning_remarks = var_iter(data, target_col, max_bins)\n",
    "    print(\"------------------IV and WOE calculated for individual groups.------------------\")\n",
    "    print(\"Total time elapsed: {} minutes\".format(round((time.time() - func_start_time) / 60, 3)))\n",
    "    \n",
    "    woe_iv[\"feature\"] = woe_iv[\"feature\"].replace(\"_bins\", \"\", regex=True)    \n",
    "    woe_iv = woe_iv[[\"feature\", \"sample_class\", \"sample_class_label\", \"sample_count\", \"min_value\", \"max_value\",\n",
    "                     \"non_event_count\", \"non_event_rate\", \"event_count\", \"event_rate\", 'distbn_non_event',\n",
    "                     'distbn_event', 'woe', 'iv']]\n",
    "    \n",
    "    iv = woe_iv.groupby(\"feature\")[[\"iv\"]].agg([\"sum\", \"count\"]).reset_index()\n",
    "    print(\"------------------Aggregated IV values for features calculated.------------------\")\n",
    "    print(\"Total time elapsed: {} minutes\".format(round((time.time() - func_start_time) / 60, 3)))\n",
    "    \n",
    "    iv.columns = [\"feature\", \"iv\", \"number_of_classes\"]\n",
    "    null_percent_data=pd.DataFrame(data.isnull().mean()).reset_index()\n",
    "    null_percent_data.columns=[\"feature\", \"feature_null_percent\"]\n",
    "    iv=iv.merge(null_percent_data, on=\"feature\", how=\"left\")\n",
    "    print(\"------------------Null percent calculated in features.------------------\")\n",
    "    print(\"Total time elapsed: {} minutes\".format(round((time.time() - func_start_time) / 60, 3)))\n",
    "    iv = iv.merge(binning_remarks, on=\"feature\", how=\"left\")\n",
    "    woe_iv = woe_iv.merge(iv[[\"feature\", \"iv\", \"remarks\"]].rename(columns={\"iv\": \"iv_sum\"}), on=\"feature\", how=\"left\")\n",
    "    print(\"------------------Binning remarks added and process is complete.------------------\")\n",
    "    print(\"Total time elapsed: {} minutes\".format(round((time.time() - func_start_time) / 60, 3)))\n",
    "    return iv, woe_iv.replace({\"Missing\": np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "837eba54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/cd80test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ubuntu/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/arraylike.py:364: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/ubuntu/anaconda3/envs/cd80test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ubuntu/anaconda3/envs/cd80test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ubuntu/anaconda3/envs/cd80test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/ubuntu/anaconda3/envs/cd80test/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3553: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .cat accessor with a 'category' dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3441/2028487068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'APPLICATION_DATE'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'APPLICATION_DATE_bins'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0miv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwoe_iv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_iv_woe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"DEFAULT_LABEL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwoe_iv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3441/2085379728.py\u001b[0m in \u001b[0;36mget_iv_woe\u001b[0;34m(data, target_col, max_bins)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_iv_woe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mfunc_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mwoe_iv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinning_remarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------------------IV and WOE calculated for individual groups.------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total time elapsed: {} minutes\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfunc_start_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3441/2085379728.py\u001b[0m in \u001b[0;36mvar_iter\u001b[0;34m(data, target_col, max_bins)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mremarks_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"remarks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mremarks\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0magg_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miv_woe_4iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0mremarks_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mc_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"remarks\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;31m# print(\"---{} seconds. c_i: {}----\".format(round(time.time() - c_i_start_time, 2), c_i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3441/2085379728.py\u001b[0m in \u001b[0;36miv_woe_4iter\u001b[0;34m(binned_data, target_col, class_col)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miv_woe_4iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinned_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"_bins\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mbinned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_categories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Missing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mbinned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinned_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Missing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         temp_groupby = binned_data.groupby(class_col).agg({class_col.replace(\"_bins\", \"\"):[\"min\", \"max\"],\n",
      "\u001b[0;32m~/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cd80test/lib/python3.7/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   2608\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2610\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .cat accessor with a 'category' dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_delegate_property_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .cat accessor with a 'category' dtype"
     ]
    }
   ],
   "source": [
    "train_f = pd.read_csv(\"./data/train/feature.csv\")\n",
    "train_l = pd.read_csv(\"./data/train/label.csv\")\n",
    "data = pd.merge(train_f, train_l)\n",
    "data.rename(columns={'APPLICATION_DATE':'APPLICATION_DATE_bins'}, inplace = True)\n",
    "\n",
    "iv, woe_iv = get_iv_woe(data.copy(), target_col=\"DEFAULT_LABEL\", max_bins=20)\n",
    "print(iv.shape, woe_iv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3862354",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_iv[woe_iv['feature'] == 'v010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c746f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "woe_iv.to_csv(\"woe_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91fbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cd80test",
   "language": "python",
   "name": "cd80test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
